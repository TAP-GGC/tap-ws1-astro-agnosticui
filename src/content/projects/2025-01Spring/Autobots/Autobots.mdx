---
title: Autobots
id: autobots
desc : Use Scratch based coding and Google's teachable machine to program and control a Mbot using hands or symbols!
github: https://github.com/TAP-GGC/AutoBots
students: [
  "jonathan-tran", "krishan-bhalsod", "isaiah-gorman"
]
instructors: [
  "cengiz-gunay", "cindy-robertson"
] 
techs: [
  "mbot mega",  "mblock",
  "ai",  "artificial intelligence"
]
videos: [
  {src: "nPc_onJ8ggs?si=HB9EN36hapILZ6l2", caption: ""} ,
  {src: "oV6r2fmOg98?si=2WouGrz4BYaPluQ3", caption: ""} ,
]
events: []
semester: spring
year: 2025
levels: ["k-12","college","middle-school"]  
difficulty: ["intermediate"]
durationMins: [  30, 60, 90]
publishedDate: 2025-04-28
relatedIds: [
  "jedi-sphero", "dancing sphero", "mbot mega", "mblock", "thebeepbops", "ai-diva", "wanda", "code-nator", "artify-ai", "drone-reality", "ball-is-life",  "tech-gold-fish"
]
images:
  [
    { src: "./teamautobots.jpg", alt: "Team Members" },
    { src: "./WorkshopSS1.jpg", alt: "Workshop1" },
    { src: "./WorkshopSS3.jpg", alt: "Workshop2" },
    { src: "./WorkshopSS4.jpg", alt: "Workshop3" },
    { src: "./ExpoSS1.jpg", alt: "Tap Expo" },
    
  ]
imageLogoLight: ./3dcnn.png
curator: ["kelechi-ariwodo"]
videoAd: "oV6r2fmOg98?si=2WouGrz4BYaPluQ3"
---

import { Image } from "astro:assets";
import Photo from '/src/components/astro/Photo.astro';
import GroupPhoto from './teamautobots.jpg';
import Logo from '/src/components/astro/Logo.astro';
import mLogo from 'mBlockLogo.png';

#### **Team Members:**  
<Photo src={GroupPhoto.src} alt="AutoBots Team Photo" caption="Left to Right: Jonathan Tran, Krishan Bhalsod, Isaiah Gorman"/>

{/* CONTENT BLOCK */}

## About
Autobots introduces students to the exciting world of artificial intelligence, with a special focus on how machines learn to "see" using image recognition. Using Google's TeachableMachine, students train their own AI models by creating unique hand gestures that control a robot's movements. This hands-on challenge not only makes learning fun, but also shows students some of the real-world difficulties AI faces—like telling apart gestures that look very similar.

Behind the scenes, these models often rely on Convolutional Neural Networks (CNNs), a special type of AI architecture that mimics how our brains process visual information. CNNs help the computer pick out patterns, edges, and shapes in images so it can learn the difference between a peace sign and a thumbs-up. By experimenting with gesture control, students get a glimpse into how technologies like Tesla’s self-driving system work—and understand the challenges that come with training machines to interpret the visual world.


## Requirements
  * Access to Bluetooth and Webcam
  * MUST USE GOOGLE CHROME
  * Source Code
  * Mbot

{/* CONTENT BLOCK */}


## Outreach Activities
<li>Tap Expo, 2025, Georgia Gwinnett College </li>
<li>[Atlanta Science Festival](https://atlantasciencefestival.org/) (At Georgia Gwinnett College and Piedmont Park) </li>
<li>Class Workshops, 2025, Georgia Gwinnett College</li>

## Technology
<Logo src={mLogo.src} alt="mBlock Logo" />

## Project Setup and Installation
[Building mBot Mega Instructions](https://support.makeblock.com/hc/en-us/articles/1500009896321-Build-mBot-Mega)

[Workshop PDF Instructions](https://github.com/TAP-GGC/AutoBots/blob/main/documents/tutorial%20materials/Workshop%20PDF.pdf)

